{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from func_tools import normalize, get_labels, cnn_data_reshaping, reshape_lob_levels, plot_labels, label_insights, back_to_labels, get_pnl, get_strategy_pnl, plot_labels_line\n",
    "import multiprocessing\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import plotly_express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict tf to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "source": [
    "## Inputs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Experiments/USDT_BTC/210115-141217-USDT_BTC-10s-10l-100-2020_04_04-2021_01_03_code_cleanup/config.json') as f:\n",
    "  config_file = json.load(f)\n",
    "config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_folder = 'Experiments'\n",
    "input_data_folder = f'{experiments_folder}/input'\n",
    "cache_folder = f'{experiments_folder}/cache'\n",
    "\n",
    "pair = 'USDT_BTC'\n",
    "frequency = timedelta(seconds=10)\n",
    "lob_depth = 10\n",
    "length = 100\n",
    "date_start = '2020_04_04'\n",
    "date_end = '2021_01_03'\n",
    "norm_type = 'dyn_z_score'\n",
    "roll = 7200 * 6\n",
    "batch_size = 64\n",
    "\n",
    "# labelling inputs\n",
    "k_plus = 15\n",
    "k_minus = 15\n",
    "alpha = 0.0045\n",
    "trading_fee=0.000712\n",
    "min_profit=0.002\n",
    "\n",
    "frequency_seconds = int(frequency.total_seconds())\n",
    "os.makedirs(f'{cache_folder}/{pair}', exist_ok=True)\n",
    "\n",
    "# Data import - needs to be adjusted importing from several files using Dask\n",
    "input_file_name = f'{pair}--{lob_depth}lev--{frequency_seconds}sec--{date_start}--{date_end}.csv.gz'\n",
    "\n",
    "normalized_train_file = f'{cache_folder}/{pair}/TRAIN--{norm_type}-{roll}--{input_file_name}'\n",
    "normalized_test_file = f'{cache_folder}/{pair}/TEST--{norm_type}-{roll}--{input_file_name}'\n",
    "\n",
    "top_ob_train_file = f'{cache_folder}/{pair}/TRAIN_TOP--{input_file_name}'\n",
    "top_ob_test_file = f'{cache_folder}/{pair}/TEST_TOP--{input_file_name}'\n",
    "\n",
    "#if os.path.isfile(normalized_test_file): # testing for one of cache files, assuming all were saved \n",
    "print(f'Reading cached {normalized_train_file}')\n",
    "train_dyn_df = pd.read_csv(normalized_train_file)\n",
    "print(f'Reading cached {normalized_test_file}')\n",
    "test_dyn_df = pd.read_csv(normalized_test_file)\n",
    "\n",
    "print(f'Reading cached {top_ob_train_file}')\n",
    "top_ob_train = pd.read_csv(top_ob_train_file)\n",
    "print(f'Reading cached {top_ob_test_file}')\n",
    "top_ob_test = pd.read_csv(top_ob_test_file) "
   ]
  },
  {
   "source": [
    "### test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data loading and predictions\n",
    "- Import normalized data (cached)\n",
    "- Get labels generated by our methodology (what we use for train and test)\n",
    "\n",
    "- Load model saved\n",
    "- Generate predictions from normalized reshaped data - predicted labels\n",
    "\n",
    "- Import original data for assessing performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train pipeline\n",
    "# Get original labels\n",
    "train_depth_dyn, train_dt_index_dyn = reshape_lob_levels(train_dyn_df, output_type='array') # 1 test dataset reshaped for model eval\n",
    "mid_px_train_dyn = pd.Series((train_depth_dyn[:,2] + train_depth_dyn[:,0]) / 2, name='mid_px') # 2 mid px from top level ob\n",
    "\n",
    "px_ts_train = top_ob_train.reset_index()[['Mid_Price']]\n",
    "\n",
    "original_train_labels = get_labels(mid_px_train_dyn, k_plus, k_minus, alpha, long_only=False) # 3 labels from mid px\n",
    "train_profit, df_train_profit = get_strategy_pnl(px_ts_train, original_train_labels, trading_fee=trading_fee, min_profit=0.002, plotting=False, return_df=True)\n",
    "original_cleaned_train_labels = df_train_profit['cleaned_labels'] # 3 bis cleaned labels\n",
    "\n",
    "encoded_test_labels = np_utils.to_categorical(original_cleaned_labels.values,3) # 4 test labels one hot encoded for eval#\n",
    "\n",
    "print('\\n##### Dirty Labels #####')\n",
    "label_insights(original_train_labels)\n",
    "print('\\n##### Cleaned Labels #####')\n",
    "label_insights(original_cleaned_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_strategy_pnl(px_ts_train, original_train_labels, trading_fee=trading_fee, min_profit=0.002, plotting=True, return_df=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pipeline\n",
    "test_depth_dyn, test_dt_index_dyn = reshape_lob_levels(test_dyn_df, output_type='array') # 1 test dataset reshaped for model eval\n",
    "mid_px_test_dyn = pd.Series((test_depth_dyn[:,2] + test_depth_dyn[:,0]) / 2, name='mid_px') # 2 mid px from top level ob\n",
    "\n",
    "px_ts_test = top_ob_test.reset_index()[['Mid_Price']]\n",
    "\n",
    "original_labels = get_labels(mid_px_test_dyn, k_plus, k_minus, alpha, long_only=False) # 3 labels from mid px\n",
    "profit, df_profit = get_strategy_pnl(px_ts_test, original_labels, trading_fee=trading_fee, min_profit=0.002, plotting=False, return_df=True)\n",
    "original_cleaned_labels = df_profit['cleaned_labels'] # 3 bis cleaned labels\n",
    "\n",
    "encoded_test_labels = np_utils.to_categorical(original_cleaned_labels.values,3) # 4 test labels one hot encoded for eval#\n",
    "\n",
    "print('\\n##### Dirty Labels #####')\n",
    "label_insights(original_labels)\n",
    "print('\\n##### Cleaned Labels #####')\n",
    "label_insights(original_cleaned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels_line(df_profit['px'][500000:], df_profit['cleaned_labels'][500000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid px linechart - sampled\n",
    "sample_size = 6 * 60#6*60*24 # daily\n",
    "dynz_gap = int(roll / sample_size)\n",
    "hourly_mid_line = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "y_train = top_ob_train['Mid_Price'].iloc[::sample_size].values\n",
    "x_train = np.arange(y_train.shape[0])\n",
    "y_test = top_ob_test['Mid_Price'].iloc[::sample_size].values\n",
    "x_test = np.arange(y_train.shape[0] + dynz_gap, y_train.shape[0] + y_test.shape[0] + dynz_gap)\n",
    "\n",
    "y_train_dynz = mid_px_train_dyn.iloc[::sample_size].values  \n",
    "x_train_dynz = np.arange(y_train.shape[0])\n",
    "y_test_dynz = mid_px_test_dyn.iloc[::sample_size].values\n",
    "x_test_dynz = np.arange(y_train.shape[0] + dynz_gap, y_train.shape[0] + y_test.shape[0] + dynz_gap)\n",
    "\n",
    "hourly_mid_line.add_trace(go.Scatter(y=y_train, x=x_train, name='mid_train'), secondary_y=False)\n",
    "hourly_mid_line.add_trace(go.Scatter(y=y_test, x=x_test, name='mid_test'), secondary_y=False)\n",
    "hourly_mid_line.add_trace(go.Scatter(y=y_train_dynz, x=x_train_dynz, name='mid_train_dynz',\n",
    "    marker=dict(color='rgba(44, 130, 201, 0.3)')), secondary_y=True)\n",
    "hourly_mid_line.add_trace(go.Scatter(y=y_test_dynz, x=x_test_dynz, name='mid_test_dynz',\n",
    "    marker=dict(color='rgba(240, 52, 52, 0.3)')), secondary_y=True)\n",
    "\n",
    "hourly_mid_line.update_layout(title='<b>Sampled mid</b>')\n",
    "hourly_mid_line.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in glob.glob('Experiments/*'):\n",
    "#     for file in glob.glob(f'{name}/*'):\n",
    "#         print(file)\n",
    "model_name = '/home/federico/Python_vsc_dir/RL_Trader/Experiments/USDT_BTC/210115-141217-USDT_BTC-10s-10l-100-2020_04_04-2021_01_03_code_cleanup/210115-141217-USDT_BTC-10s-10l-100-2020_04_04-2021_01_03_code_cleanup.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously saved weights and evaluate model performance\n",
    "deep_lob_loaded = tf.keras.models.load_model(model_name)\n",
    "generator_test = TimeseriesGenerator(\n",
    "    test_depth_dyn,\n",
    "    encoded_test_labels,\n",
    "    100,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def evaluate_model(model):\n",
    "    # Re-evaluate the model\n",
    "    loss, acc = model.evaluate(generator_test, verbose=2)\n",
    "    print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(deep_lob_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels\n",
    "predictions_prob = deep_lob_loaded.predict(generator_test, verbose=1)\n",
    "map_labels = np.vectorize(back_to_labels) # vectorize back to labels from func_tools\n",
    "predicted_labels = pd.Series(map_labels(np.argmax(predictions_prob,axis=1)), name='predicted_labels') # back to original 1,0,-1\n",
    "\n",
    "label_insights(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import original data\n",
    "# data = pd.read_csv(f'{root_caching_folder}/{security}/data-cache-10s.csv', index_col=0)\n",
    "# #lob_depth = data['Level'].max() + 1\n",
    "# train_test_split = int((data.shape[0] / lob_depth) * 0.7) # slice reference for train and test\n",
    "# test_timestamps = data['Datetime'].unique()[train_test_split:] # timestamps array\n",
    "# test_cached_data = data[data['Datetime'].isin(test_timestamps)].set_index(['Datetime', 'Level']) # split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pnl from normalized labels and real px timeseries (alway postive prices)\n",
    "# roll_shift = roll+1 # rolling period for dyn z score - + 1 from shift in ft.normalize\n",
    "# top_ob = test_cached_data[test_cached_data.index.get_level_values(1)==0][roll_shift:]\n",
    "# top_ob['Mid_Price'] = (top_ob['Ask_Price'] + top_ob['Bid_Price']) / 2\n",
    "# top_ob['Spread'] = (top_ob['Ask_Price'] - top_ob['Bid_Price']) / top_ob['Mid_Price']\n",
    "# top_ob['merge_index'] = top_ob.reset_index().index.values # useful for merging later\n",
    "# mid_px = top_ob.reset_index()['Mid_Price']\n"
   ]
  },
  {
   "source": [
    "## Preparing data for backtesting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#idx_simulated_shifted = np.concatenate((0, idx_simulated[1:], np.array([df_simulated.shape[0]])))\n",
    "def get_all_trades_performance(df_pnl, idx_pnl, trading_fee):\n",
    "    '''Generate a dataframe with one row for each trade with all relevant information to assess a strategy\n",
    "\n",
    "    Arguments:\n",
    "    df_pnl -- pandas dataframe with mid, bid and ask prices info\n",
    "    idx_pnl -- numpy array with indices of when trades occur\n",
    "    trading_fee -- float indicating fixed transaction cost (exchange determined)\n",
    "    '''\n",
    "\n",
    "    start_idx = np.concatenate((np.array([0]), idx_pnl))\n",
    "    end_idx = np.concatenate((idx_pnl, np.array([df_pnl.shape[0]])))\n",
    "    trades = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # initiate an array with n values - number of columns\n",
    "\n",
    "    def calculate_return(start_px, end_px, trade_type, trading_fee):\n",
    "        if trade_type == 1:\n",
    "            pctg_chg = (((end_px - (end_px*trading_fee)) - (start_px+(start_px*trading_fee)))/(start_px)) * trade_type # buy trade\n",
    "        elif trade_type == -1:\n",
    "            pctg_chg = (((end_px + (end_px*trading_fee)) - (start_px-(start_px*trading_fee)))/(start_px)) * trade_type # sell trade\n",
    "        else:\n",
    "            pctg_chg = 0 # neutral\n",
    "\n",
    "        return pctg_chg\n",
    "\n",
    "    # loop through each trade\n",
    "    for start_trade, end_trade in zip(start_idx, end_idx):\n",
    "\n",
    "        try:\n",
    "            \n",
    "            df = df_pnl[start_trade:end_trade] # slice of with single trade\n",
    "            df_exit_slippage = df_pnl[end_trade+1:end_trade+3]\n",
    "\n",
    "            trade_type = df['labels'].values[0] # direction from first label\n",
    "\n",
    "            start_mid_px = df['Mid_Price'].values[0]\n",
    "            end_mid_px = df['Mid_Price'].values[-1] \n",
    "\n",
    "            start_ask_px = df['Ask_Price'].values[0]\n",
    "            end_ask_px = df['Ask_Price'].values[-1]\n",
    "\n",
    "            start_bid_px = df['Bid_Price'].values[0]\n",
    "            end_bid_px = df['Bid_Price'].values[-1]\n",
    "\n",
    "            if df.shape[0] == 1:\n",
    "                start_mid_px_slip = df_exit_slippage['Mid_Price'].values[0]\n",
    "                start_ask_px_slip = df_exit_slippage['Ask_Price'].values[0]\n",
    "                start_bid_px_slip = df_exit_slippage['Bid_Price'].values[0]\n",
    "\n",
    "            else:\n",
    "                start_mid_px_slip = df['Mid_Price'].values[1]\n",
    "                start_ask_px_slip = df['Ask_Price'].values[1]\n",
    "                start_bid_px_slip = df['Bid_Price'].values[1]\n",
    "\n",
    "            end_mid_px_slip_1 = df_exit_slippage['Mid_Price'].values[0] # px at which trade is closed is when new signal is generated\n",
    "            end_mid_px_slip_2 = df_exit_slippage['Mid_Price'].values[1] # or somewhere between that and the next timestep - time to generate order\n",
    "\n",
    "            end_ask_px_slip_1 = df_exit_slippage['Ask_Price'].values[0]\n",
    "            end_ask_px_slip_2 = df_exit_slippage['Ask_Price'].values[1]\n",
    "\n",
    "            end_bid_px_slip_1 = df_exit_slippage['Bid_Price'].values[0]\n",
    "            end_bid_px_slip_2 = df_exit_slippage['Bid_Price'].values[1]\n",
    "\n",
    "            gross_trade_return = calculate_return(start_mid_px, end_mid_px, trade_type, 0) # gross performance\n",
    "            \n",
    "            fees_impact = gross_trade_return - calculate_return(start_mid_px, end_mid_px, trade_type, trading_fee) # net trading fee performance (entry and exit)\n",
    "\n",
    "            slippage_impact = gross_trade_return - calculate_return((start_mid_px + start_mid_px_slip)/2, (end_mid_px_slip_1 + end_mid_px_slip_2)/2, trade_type, 0) # gross minus slippage only using mid\n",
    "\n",
    "            if trade_type == 1:\n",
    "                spread_impact = gross_trade_return - calculate_return((start_ask_px + start_ask_px_slip)/2, (end_bid_px_slip_1 + end_bid_px_slip_2)/2, trade_type, 0) - (slippage_impact) # net of bbo spread performance (round-trip)\n",
    "                net_return = calculate_return((start_ask_px + start_ask_px_slip)/2, (end_bid_px_slip_1 + end_bid_px_slip_2)/2, trade_type, trading_fee) # net return all-in\n",
    "            elif trade_type == -1:\n",
    "                spread_impact = gross_trade_return - calculate_return((start_bid_px + start_bid_px_slip)/2, (end_ask_px_slip_1 + end_ask_px_slip_2)/2, trade_type, 0) - (slippage_impact)# net of bbo spread performance (round-trip)\n",
    "                net_return = calculate_return((start_bid_px + start_bid_px_slip)/2, (end_ask_px_slip_1 + end_ask_px_slip_2)/2, trade_type, trading_fee) # net return all-in\n",
    "            elif trade_type == 0:\n",
    "                spread_impact = gross_trade_return # 0\n",
    "                net_return = gross_trade_return # 0\n",
    "\n",
    "            mid_px_std = (np.log(df['Mid_Price']) - np.log(df['Mid_Price'].shift(1))).std()\n",
    "            sharpe_ratio = net_return / mid_px_std # std of log gross returns - would be better with net, but this is a fair approx\n",
    "\n",
    "            array_to_append = np.array([start_trade, \n",
    "                                        end_trade, \n",
    "                                        start_mid_px, \n",
    "                                        start_mid_px_slip, \n",
    "                                        end_mid_px,\n",
    "                                        end_mid_px_slip_1,\n",
    "                                        end_mid_px_slip_2,\n",
    "                                        start_ask_px, \n",
    "                                        start_ask_px_slip, \n",
    "                                        end_ask_px,\n",
    "                                        end_ask_px_slip_1,\n",
    "                                        end_ask_px_slip_2,\n",
    "                                        start_bid_px, \n",
    "                                        start_bid_px_slip, \n",
    "                                        end_bid_px,\n",
    "                                        end_bid_px_slip_1,\n",
    "                                        end_bid_px_slip_2,\n",
    "                                        trade_type, \n",
    "                                        gross_trade_return, \n",
    "                                        fees_impact, \n",
    "                                        spread_impact, \n",
    "                                        slippage_impact, \n",
    "                                        net_return,\n",
    "                                        mid_px_std,\n",
    "                                        sharpe_ratio])\n",
    "                                        \n",
    "            trades = np.vstack([trades, array_to_append])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'{e} at start_idx = {start_trade} and end_idx = {end_trade}. Shape dataframe = {df_pnl.shape[0]}')\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info() # select cell and press ctrl+L to show rows in jupyter notebook\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            print(f'Error details: {exc_type}, {fname}, {exc_tb.tb_lineno}')\n",
    "            array_to_append = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "            trades = np.vstack([trades, array_to_append])\n",
    "            continue\n",
    "    df_trades_all = pd.DataFrame(trades, \n",
    "                                columns=[\n",
    "                                    'start_trade', \n",
    "                                    'end_trade', \n",
    "                                    'start_mid_px',\n",
    "                                    'start_mid_px_slip', \n",
    "                                    'end_mid_px',\n",
    "                                    'end_mid_px_slip_1',\n",
    "                                    'end_mid_px_slip_2',\n",
    "                                    'start_ask_px', \n",
    "                                    'start_ask_px_slip', \n",
    "                                    'end_ask_px',\n",
    "                                    'end_ask_px_slip_1',\n",
    "                                    'end_ask_px_slip_2',\n",
    "                                    'start_bid_px', \n",
    "                                    'start_bid_px_slip',\n",
    "                                    'end_bid_px',\n",
    "                                    'end_bid_px_slip_1',\n",
    "                                    'end_bid_px_slip_2',\n",
    "                                    'direction', \n",
    "                                    'gross_trade_return', \n",
    "                                    'fees_impact', \n",
    "                                    'spread_impact', \n",
    "                                    'slippage_impact', \n",
    "                                    'net_return',\n",
    "                                    'mid_px_std',\n",
    "                                    'sharpe_ratio'\n",
    "                                    ])\n",
    "    df_trades_all['trade_length'] = df_trades_all['end_trade'] - df_trades_all['start_trade'] # how many periods a trade lasts\n",
    "    df_trades_all['winning_net_trades'] = df_trades_all.apply(lambda x: 1 if x['net_return']>0 else (-1 if x['net_return']<0 else 0), axis=1) # flag for winning trades\n",
    "    \n",
    "    return df_trades_all[(df_trades_all == 0).sum(axis=1) != df_trades_all.shape[1]] # remove rows full of zeros   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_all_trades(df_pnl, idx_pnl, trading_fee):\n",
    "    df_trades_all = get_all_trades_performance(df_pnl, idx_pnl, trading_fee)\n",
    "\n",
    "    # trades without \"zeros\" - used to calculate stats\n",
    "    df_trades_in = df_trades_all[df_trades_all['direction'] != 0]\n",
    "    # assign a timestamp to start trade. Quicker than doing it in the loop:\n",
    "    df_trades_in = pd.merge(df_trades_in, top_ob_test.reset_index()[['merge_index', 'Datetime']], how='left', left_on='start_trade', right_on='merge_index')\n",
    "    df_trades_in['Datetime'] = pd.to_datetime(df_trades_in['Datetime'])\n",
    "\n",
    "    return df_trades_all, df_trades_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cleaned_labels.shape, predicted_labels.shape, px_ts_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error: I was initially using mid px from norm rather than real px. Norm px has neg values, skewing labellinge etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trade performance dataframe for original labels\n",
    "# profit, df_simulated = get_strategy_pnl(px_ts_test, original_cleaned_labels, trading_fee=trading_fee, min_profit=0.002, plotting=False, return_df=True) #already run above\n",
    "# df_simulated = pd.merge(df_simulated, top_ob_test, left_index=True, right_index=True) # merge with top ob to get mid, bid and ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate trade performance dataframe for predicted labels\n",
    "# # need check here on dataframes shapes. Or better, merge by datetime rather thank a number, less error prone\n",
    "# pnl_prediction, df_prediction = get_strategy_pnl(px_ts_test[100:].reset_index()['Mid_Price'], predicted_labels, trading_fee=trading_fee, min_profit=0.002, plotting=False, return_df=True) \n",
    "# df_prediction = pd.merge(df_prediction, top_ob_test[100:].reset_index(), left_index=True, right_index=True) # merge with top ob to get mid, bid and ask - lag top_ob by 100 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trade performance dataframe for predicted labels\n",
    "# need check here on dataframes shapes. Or better, merge by datetime rather thank a number, less error prone\n",
    "pnl_predicted, df_predicted, idx_predicted = get_pnl(px_ts_test[100:].reset_index()['Mid_Price'], predicted_labels, trading_fee=0.000712)\n",
    "df_predicted = pd.merge(df_predicted, top_ob_test[100:].reset_index(), left_index=True, right_index=True) # merge with top ob to get mid, bid and ask - lag top_ob by 100 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trades_all, df_trades_in = get_df_all_trades(df_simulated, idx_simulated, trading_fee)\n",
    "df_trades_all, df_trades_in = get_df_all_trades(df_predicted, idx_predicted, trading_fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trades_all_original, df_trades_in_original = get_df_all_trades(df_simulated, idx_simulated, trading_fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trades_in[0:5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.line(y=daily_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.line(y=daily_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mid px linechart - sampled\n",
    "# hourly_mid_line = go.Figure()\n",
    "# hourly_mid_line.add_trace(go.Scatter(y=mid_px.iloc[::6*60*24].values, name='mid'))\n",
    "\n",
    "# hourly_mid_line.update_layout(title='<b>Daily sampled mid</b>')\n",
    "# hourly_mid_line.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Strategy Overview"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trades_in['direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters\n",
    "trades_in_filtered = df_trades_in#df_trades_in[(df_trades_in['trade_length'] >= 50) & (df_trades_in['direction'].isin([1.0, -1.0]))]\n",
    "print(f'{trades_in_filtered.shape[0]} trades filtered out of {df_trades_in.shape[0]} total trades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_in_filtered.index[0]\n",
    "trades_in_filtered.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_px_test_dyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_timesteps = 100\n",
    "#trade_id = 46\n",
    "\n",
    "\n",
    "slice_start = int(trades_in_filtered[trades_in_filtered.index==trades_in_filtered.index[0]]['start_trade'])\n",
    "slice_end = int(trades_in_filtered[trades_in_filtered.index==trades_in_filtered.index[-1]]['end_trade'])#3877#int(trades_in_filtered.iloc[trade_id]['end_trade'])\n",
    "trades_in_plotting = trades_in_filtered[(trades_in_filtered.index>=slice_start)&(trades_in_filtered.index<=slice_end)]\n",
    "# filter with slice start and end the trades_in_filtered\n",
    "\n",
    "#Single trades chart -largest chart\n",
    "long_start = trades_in_plotting[trades_in_plotting['direction']==1][['start_trade', 'start_ask_px', 'start_ask_px_slip']]\n",
    "long_start['start_px_long'] = (long_start['start_ask_px'] + long_start['start_ask_px_slip'])/2\n",
    "\n",
    "long_end = trades_in_plotting[trades_in_plotting['direction']==1][['end_trade', 'end_bid_px_slip_1', 'end_bid_px_slip_2']]\n",
    "long_end['end_px_long'] = (long_end['end_bid_px_slip_1'] + long_end['end_bid_px_slip_2'])/2\n",
    "\n",
    "short_start = trades_in_plotting[trades_in_plotting['direction']==-1][['start_trade', 'start_bid_px', 'start_bid_px_slip']]\n",
    "short_start['start_px_short'] = (short_start['start_bid_px'] + short_start['start_bid_px_slip'])/2\n",
    "\n",
    "short_end = trades_in_plotting[trades_in_plotting['direction']==-1][['end_trade', 'end_ask_px_slip_1', 'end_ask_px_slip_2']]\n",
    "short_end['end_px_short'] = (short_end['end_ask_px_slip_1'] + short_end['end_ask_px_slip_2'])/2\n",
    "\n",
    "\n",
    "pred_prob_fig = make_subplots(rows=3, cols=1, specs=[[{\"secondary_y\": False}], [{\"secondary_y\": False}], [{\"secondary_y\": False}]],\n",
    "    subplot_titles=(\"Prediction Probability\", \"\"), shared_xaxes=True, row_heights=[0.4, 0.3, 0.3], vertical_spacing = 0.0)\n",
    "\n",
    "plot_idx = np.arange(slice_start, slice_end)\n",
    "pred_prob_fig.add_trace(go.Scatter(y=predictions_prob[:,1][slice_start:slice_end], x=plot_idx, name = 'Prob of long'), secondary_y=False)\n",
    "pred_prob_fig.add_trace(go.Scatter(y=predictions_prob[:,2][slice_start:slice_end], x=plot_idx, name = 'Prob of short'), secondary_y=False)\n",
    "pred_prob_fig.add_trace(go.Scatter(y=predictions_prob[:,0][slice_start:slice_end], x=plot_idx, name = 'Prob of neutral'), secondary_y=False)\n",
    "pred_prob_fig.add_trace(go.Scatter(y=top_ob_test['Mid_Price'][slice_start+pred_timesteps:slice_end+pred_timesteps], x=plot_idx, name = 'Mid Px'), row=2, col=1, secondary_y=False)\n",
    "pred_prob_fig.add_trace(go.Scatter(y=mid_px_test_dyn[slice_start+pred_timesteps:slice_end+pred_timesteps], x=plot_idx, name = 'Norm Mid Px'), row=3, col=1, secondary_y=False)\n",
    "\n",
    "#plot long trade prices\n",
    "pred_prob_fig.add_trace(go.Scatter(y=long_start['start_px_long'], x=long_start['start_trade'], mode='markers', marker_size=5, name='long entry'), row=2, col=1) # set color and size\n",
    "pred_prob_fig.add_trace(go.Scatter(y=long_end['end_px_long'], x=long_end['end_trade'], mode='markers', marker_size=5, name='long exit', marker=dict(color='Navy')), row=2, col=1)\n",
    "\n",
    "# plot short trade prices\n",
    "pred_prob_fig.add_trace(go.Scatter(y=short_start['start_px_short'], x=short_start['start_trade'], mode='markers', marker_size=5, name='short entry'), row=2, col=1) # set color and size\n",
    "pred_prob_fig.add_trace(go.Scatter(y=short_end['end_px_short'], x=short_end['end_trade'], mode='markers', marker_size=5, name='short exit'), row=2, col=1)\n",
    "\n",
    "pred_prob_fig.update_layout(width=1400, height=900) \n",
    "pred_prob_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg daily stats - to verify\n",
    "daily_returns = trades_in_filtered.groupby([trades_in_filtered['Datetime'].dt.floor('D')])['net_return'].sum()\n",
    "df_trades_in['dailized_std'] = trades_in_filtered['mid_px_std'] * np.sqrt(trades_in_filtered['trade_length'] / (6*60*24))\n",
    "daily_std = trades_in_filtered.groupby([trades_in_filtered['Datetime'].dt.floor('D')])['dailized_std'].sum()\n",
    "daily_sharpe = daily_returns / daily_std\n",
    "#daily_sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get backtesting notional values associated with the strategy\n",
    "cumulative_no = ((trades_in_filtered['net_return']+1) * 1000 - 1000).cumsum() + 1000\n",
    "compound_no = (trades_in_filtered['net_return']+1).cumprod() * 1000\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Scatter(x=trades_in_filtered['start_trade'], y=cumulative_no, name='cumulative notional'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=trades_in_filtered['start_trade'], y=compound_no, name='compound notional'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=trades_in_filtered['start_trade'], y=trades_in_filtered['start_mid_px'], name='mid price'), secondary_y=True)\n",
    "fig.update_layout(title='<b>Notional value</b>')\n",
    "fig.update_yaxes(title_text='<b>USD</b>', secondary_y=False)\n",
    "fig.update_yaxes(title_text='Currency', secondary_y=True)\n",
    "fig.show()\n",
    "\n",
    "cumulative_no.iloc[-1], compound_no.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_count = trades_in_filtered.groupby([pd.Grouper(freq='1d', key='Datetime'), 'direction'])['start_trade'].count().reset_index()\n",
    "trades_over_time = px.bar(df_grouped_count, x='Datetime', y='start_trade', color=df_grouped_count['direction'].astype('str'), title=\"<b>Number of trades over time</b>\")\n",
    "trades_over_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trades_in_filtered[trades_in_filtered['direction']==1][['start_trade', 'end_trade', 'direction', 'start_ask_px', 'start_ask_px_slip']]\n",
    "# def define_prices(x):\n",
    "#     if\n",
    "\n",
    "# long_start['start_px_long'] = (long_start['start_ask_px'] + long_start['start_ask_px_slip'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single trades chart -largest chart\n",
    "long_start = trades_in_filtered[trades_in_filtered['direction']==1][['start_trade', 'start_ask_px', 'start_ask_px_slip']]\n",
    "long_start['start_px_long'] = (long_start['start_ask_px'] + long_start['start_ask_px_slip'])/2\n",
    "\n",
    "long_end = trades_in_filtered[trades_in_filtered['direction']==1][['end_trade', 'end_bid_px_slip_1', 'end_bid_px_slip_2']]\n",
    "long_end['end_px_long'] = (long_end['end_bid_px_slip_1'] + long_end['end_bid_px_slip_2'])/2\n",
    "\n",
    "short_start = trades_in_filtered[trades_in_filtered['direction']==-1][['start_trade', 'start_bid_px', 'start_bid_px_slip']]\n",
    "short_start['start_px_short'] = (short_start['start_bid_px'] + short_start['start_bid_px_slip'])/2\n",
    "\n",
    "short_end = trades_in_filtered[trades_in_filtered['direction']==-1][['end_trade', 'end_ask_px_slip_1', 'end_ask_px_slip_2']]\n",
    "short_end['end_px_short'] = (short_end['end_ask_px_slip_1'] + short_end['end_ask_px_slip_2'])/2\n",
    "\n",
    "\n",
    "# exec_chart = px.line(title='<b>Linechart</b>', width=1200, height=600)\n",
    "# exec_chart.add_trace(go.Scatter(y=top_ob['Mid_Price'], x=top_ob.reset_index().index.values, name='mid')) # date: x=top_ob.index.get_level_values(0)\n",
    "# exec_chart.add_trace(go.Scatter(y=long_start['start_px_long'], x=long_start['start_trade'], mode='markers', marker_size=5, name='long entry')) # set color and size\n",
    "# exec_chart.add_trace(go.Scatter(y=long_end['end_px_long'], x=long_end['end_trade'], mode='markers', marker_size=5, name='long exit'))\n",
    "\n",
    "# exec_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_in_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot net return distribution\n",
    "trades = [trades_in_filtered['net_return'].values]\n",
    "labels = ['Trades']\n",
    "fig = ff.create_distplot(trades, labels, bin_size = 0.0001)\n",
    "# Add shapes\n",
    "avg = np.mean(trades)\n",
    "stdev = np.std(trades)\n",
    "\n",
    "fig.add_shape(type=\"line\", yref='paper',\n",
    "    x0=avg, y0=0, x1=avg, y1=1,\n",
    "    line=dict(color=\"RoyalBlue\",width=2)\n",
    ")\n",
    "\n",
    "fig.add_shape(type=\"line\", yref='paper',\n",
    "    x0=avg+stdev, y0=0, x1=avg+stdev, y1=1,\n",
    "    line=dict(color=\"RoyalBlue\",width=2, dash=\"dot\")\n",
    ")\n",
    "\n",
    "fig.add_shape(type=\"line\", yref='paper',\n",
    "    x0=avg-stdev, y0=0, x1=avg-stdev, y1=1,\n",
    "    line=dict(color=\"RoyalBlue\",width=2, dash=\"dot\")\n",
    ")\n",
    "\n",
    "fig.add_shape(type=\"line\", yref='paper',\n",
    "    x0=0, y0=0, x1=0, y1=1,\n",
    "    line=dict(color=\"Black\",width=2, dash=\"dashdot\")\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(title=\"<b>Trades distribution - net return</b>\", width=1200, height=600, xaxis=dict(tickformat=',.3%'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trade lengths\n",
    "max_trade_length = int(trades_in_filtered['trade_length'].max())\n",
    "hist_trade_length = px.histogram(trades_in_filtered, x='trade_length', color='direction', title='<b>Trade length</b>')\n",
    "avg = trades_in_filtered['trade_length'].mean() # average trade length\n",
    "hist_trade_length.add_shape(type=\"line\", yref='paper',\n",
    "    x0=avg, y0=0, x1=avg, y1=1,\n",
    "    line=dict(color=\"Black\",width=2, dash=\"dashdot\")\n",
    ")\n",
    "hist_trade_length.show()\n",
    "\n",
    "# Plot net returns (by length and individual trades)\n",
    "hist_ret_len = px.histogram(trades_in_filtered, x='trade_length', y='net_return', histfunc='avg', color='direction', nbins=max_trade_length, title='<b>Net Return by trade length</b>')\n",
    "hist_ret_len.update_layout(yaxis=dict(tickformat=',.3%'))\n",
    "hist_ret_len.show()\n",
    "\n",
    "avg_net_by_length = trades_in_filtered.groupby('trade_length')['net_return'].mean()\n",
    "ret_len_scatter = px.scatter(trades_in_filtered, x='trade_length', y='net_return', color=trades_in_filtered['direction'].astype('str'), opacity=0.3, title='<b>Net return single trades</b>')\n",
    "ret_len_scatter.add_trace(go.Scatter(x=avg_net_by_length.index, y=avg_net_by_length.values, mode='lines', name='Average'))\n",
    "ret_len_scatter.update_layout(yaxis=dict(tickformat=',.3%'))\n",
    "ret_len_scatter.show()\n",
    "\n",
    "# Plot gross returns (by length and individual trades)\n",
    "hist_gret_len = px.histogram(trades_in_filtered, x='trade_length', y='gross_trade_return', histfunc='avg', color='direction', nbins=max_trade_length,title='<b>Gross return by trade length</b>')\n",
    "hist_gret_len.update_layout(yaxis=dict(tickformat=',.3%'))\n",
    "hist_gret_len.show()\n",
    "\n",
    "gret_len_scatter = px.scatter(trades_in_filtered, x='trade_length', y='gross_trade_return', color=trades_in_filtered['direction'].astype('str'), title='<b>Gross return single trades</b>')\n",
    "gret_len_scatter.update_layout(yaxis=dict(tickformat=',.3%'))\n",
    "gret_len_scatter.show()\n",
    "\n",
    "#fig.update_layout(barmode='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of winning trades\n",
    "pctg_winning_trades = trades_in_filtered[trades_in_filtered['winning_net_trades']==1]['winning_net_trades'].sum() / trades_in_filtered.shape[0]\n",
    "\n",
    "winning_df = trades_in_filtered[trades_in_filtered['net_return']>0]\n",
    "losing_df = trades_in_filtered[trades_in_filtered['net_return']<0]\n",
    "\n",
    "# Average winning trade return\n",
    "avg_ret_winning = winning_df['net_return'].mean()\n",
    "w_avg_ret_winning = np.average(winning_df['net_return'], weights=winning_df['trade_length'])\n",
    "\n",
    "# Average losing trade return\n",
    "avg_ret_losing = losing_df['net_return'].mean()\n",
    "w_avg_ret_losing = np.average(losing_df['net_return'], weights=losing_df['trade_length'])\n",
    "\n",
    "avg_ret_all = trades_in_filtered['net_return'].mean()\n",
    "avg_gross_all = trades_in_filtered['gross_trade_return'].mean()\n",
    "pctg_winning_trades, avg_ret_winning, avg_ret_losing, avg_ret_all, avg_gross_all"
   ]
  },
  {
   "source": [
    "## Timeseries Description"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ob['log_rets'] = (np.log(top_ob['Mid_Price']) - np.log(top_ob['Mid_Price'].shift(1))) # assumes variable is identivally distributed\n",
    "\n",
    "# np.std(top_ob['log_rets'])\n",
    "ten_s_std = np.sqrt(np.sum((top_ob['log_rets'] - top_ob['log_rets'].mean())**2)/(top_ob['log_rets'].shape[0]-1)) # -1 unbiased estimator\n",
    "one_h_std = ten_s_std * np.sqrt(6*60) # assuming statistic independence of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ob['hourly_datetime'] = pd.to_datetime(top_ob.index.get_level_values(0)).floor('H')\n",
    "top_ob['daily_datetime'] = pd.to_datetime(top_ob.index.get_level_values(0)).floor('D')\n",
    "top_ob['hour_of_day'] = pd.to_datetime(top_ob['hourly_datetime']).dt.hour\n",
    "top_ob['minute_of_day'] = pd.to_datetime(top_ob.index.get_level_values(0)).minute\n",
    "hourly_returns = top_ob.groupby(['hourly_datetime'])['log_rets'].sum() # assumption that log (continuous) returns are additive\n",
    "daily_returns = top_ob.groupby(['daily_datetime'])['log_rets'].sum() # assumption that log (continuous) returns are additive\n",
    "\n",
    "px.histogram(hourly_returns, title='<b>Hourly Log Returns</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_std = top_ob.groupby(['hourly_datetime'])['log_rets'].std() \n",
    "daily_std = top_ob.groupby(['daily_datetime'])['log_rets'].std()\n",
    "hour_of_day_std = top_ob.groupby(['hour_of_day'])['log_rets'].std() \n",
    "minute_of_day_std = top_ob.groupby(['minute_of_day'])['log_rets'].std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_scatter = px.scatter(top_ob, x=hourly_returns, y=hourly_std, title='<b>Risk - Return Scatter</b>')\n",
    "rr_scatter.show()\n",
    "\n",
    "std_over_time = px.histogram(top_ob, x=hourly_std.index, y=hourly_std, )\n",
    "std_over_time.show()\n",
    "\n",
    "std_hr_day = px.histogram(top_ob, x=hour_of_day_std.index, y=hour_of_day_std, nbins=24, title='<b>Std hour of the day</b>')\n",
    "std_hr_day.update_layout(bargap=0.15)\n",
    "std_hr_day.show()\n",
    "\n",
    "std_min_day = px.histogram(top_ob, x=minute_of_day_std.index, y=minute_of_day_std, nbins=60, title='<b>Std minute of the hour</b>')\n",
    "std_min_day.update_layout(bargap=0.15)\n",
    "std_min_day.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.line(y=top_ob['Mid_Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.line(y=top_ob['log_rets'].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.histogram(top_ob['log_rets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_length_grouped = df_trades_all.groupby('direction').agg({'trade_length':['count','mean','sum']})\n",
    "trades_length_grouped.columns = trades_length_grouped.columns.droplevel(0)\n",
    "lsn_time_pie = px.pie(trades_length_grouped, values='sum', names=trades_length_grouped.index, title='<b>Long-Short-Neutral (time)</b>')\n",
    "#lsn_time_pie.show()\n",
    "\n",
    "lsn_numb_trades_sun = px.sunburst(df_trades_all, path=['direction', 'winning_net_trades'],values='trade_length', title='<b>Long-Short-Neutral (# of trades)</b>')\n",
    "#lsn_numb_trades_sun.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}