{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
=======
   "execution_count": 2,
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
<<<<<<< HEAD
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
=======
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os, time, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# from func_tools import import_px_data, standardize, fetch_s3_trade_files, cnn_data_reshaping, reshape_lob_levels, back_to_labels, intraday_vol_ret\n",
    "import data_preprocessing as dp\n",
    "import visualization_tools as viz_t\n",
    "from labelling_class import Labels_Generator, cleaned_labels, label_insights, get_strategy_pnl\n",
    "\n",
    "import inspect\n",
    "\n",
    "import plotly_express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Reshape, Conv2D, LSTM, Dense, MaxPooling2D, BatchNormalization, LeakyReLU, concatenate, add, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
=======
   "execution_count": 3,
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 52
=======
     "execution_count": 3
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict tf to only allocate xGB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "source": [
    "## Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that start date is < than end date\n",
    "# assert lob levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
=======
   "execution_count": 6,
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = timedelta(seconds=10)\n",
    "pair = 'USDT_BTC'\n",
    "date_start = '2020-12-10'\n",
    "date_end = '2021-01-08'\n",
    "lob_depth = 10\n",
    "norm_type = 'dyn_z_score'\n",
    "roll = 7200 * 6"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 55,
=======
   "execution_count": 49,
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
<<<<<<< HEAD
      "Reading cached /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/TRAIN--dyn_z_score-43200--USDT_BTC--10lev--10sec--2020-12-10--2021-01-08.csv.gz\n",
      "Reading cached /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/TEST--dyn_z_score-43200--USDT_BTC--10lev--10sec--2020-12-10--2021-01-08.csv.gz\n",
      "Reading cached /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/TRAIN_TOP--USDT_BTC--10lev--10sec--2020-12-10--2021-01-08.csv.gz\n",
      "Reading cached /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/TEST_TOP--USDT_BTC--10lev--10sec--2020-12-10--2021-01-08.csv.gz\n",
      "train_dyn_df               Datetime  Level  Ask_Price  Bid_Price  Ask_Size  Bid_Size\n",
      "0  2020-12-15 00:00:10     -1   1.366558   1.378428 -0.620445 -0.620123\n",
      "1  2020-12-15 00:00:10      0   1.365364   1.365361 -0.560558  2.370295\n",
      "2  2020-12-15 00:00:10      1   1.379508   1.365317 -0.548553  1.295320\n",
      "test_dyn_df               Datetime  Level  Ask_Price  Bid_Price  Ask_Size  Bid_Size\n",
      "0  2021-01-05 00:00:10     -1   0.655448   0.648169 -0.636104 -0.635302\n",
      "1  2021-01-05 00:00:10      0   0.655765   0.624731  0.042762  2.329173\n",
      "2  2021-01-05 00:00:10      1   0.662876   0.617250 -0.616923 -0.302180\n",
      "top_ob_train               Datetime  Level     Ask_Price  Ask_Size     Bid_Price  Bid_Size  \\\n",
      "0  2020-12-15 00:00:00      0  19275.837040  2.025108  19275.837040  2.785514   \n",
      "1  2020-12-15 00:00:10      0  19277.215985  0.062520  19277.215985  3.122232   \n",
      "2  2020-12-15 00:00:20      0  19283.699654  0.062520  19283.699654  2.200000   \n",
=======
      "Checking for cached LOB data from 2020-12-10 to 2021-01-08\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-10.csv.gz\n",
      "74932 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-10.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-11.csv.gz\n",
      "74283 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-11.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-12.csv.gz\n",
      "74953 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-12.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-13.csv.gz\n",
      "74485 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-13.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-14.csv.gz\n",
      "75223 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-14.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-15.csv.gz\n",
      "75358 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-15.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-16.csv.gz\n",
      "74277 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-16.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-17.csv.gz\n",
      "75198 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-17.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-18.csv.gz\n",
      "75107 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-18.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-19.csv.gz\n",
      "74242 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-19.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-20.csv.gz\n",
      "73537 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-20.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-21.csv.gz\n",
      "74828 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-21.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-22.csv.gz\n",
      "75025 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-22.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-23.csv.gz\n",
      "75160 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-23.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-24.csv.gz\n",
      "73722 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-24.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-25.csv.gz\n",
      "73709 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-25.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-26.csv.gz\n",
      "73891 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-26.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-27.csv.gz\n",
      "74749 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-27.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-28.csv.gz\n",
      "74278 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-28.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-29.csv.gz\n",
      "74059 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-29.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-30.csv.gz\n",
      "74264 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-30.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2020-12-31.csv.gz\n",
      "75014 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2020-12-31.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2021-01-01.csv.gz\n",
      "74572 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2021-01-01.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2021-01-02.csv.gz\n",
      "74202 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2021-01-02.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2021-01-03.csv.gz\n",
      "74542 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2021-01-03.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2021-01-04.csv.gz\n",
      "74828 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2021-01-04.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2021-01-05.csv.gz\n",
      "74502 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2021-01-05.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2021-01-06.csv.gz\n",
      "75529 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2021-01-06.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2021-01-07.csv.gz\n",
      "74785 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2021-01-07.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/10s/2021-01-08.csv.gz\n",
      "74550 additional data points in /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/10_levels/original_frequency/2021-01-08.csv.gz\n",
      "/usr/lib/python3/dist-packages/dask/dataframe/io/csv.py:381: UserWarning: Warning gzip compression does not support breaking apart files\n",
      "Please ensure that each individual file can fit in memory and\n",
      "use the keyword ``blocksize=None to remove this message``\n",
      "Setting ``blocksize=None``\n",
      "  warn(\n",
      "Checking for cached trade data from 2020-12-10 to 2021-01-08\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-10.csv.gz\n",
      "[Errno 2] No such file or directory: '/home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-09.csv.gz'\n",
      "Non-continuous data being processed. imputing avg values for bid or ask prices at the beginning of 2020-12-10 00:00:00\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-11.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-12.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-13.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-14.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-15.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-16.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-17.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-18.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-19.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-20.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-21.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-22.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-23.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-24.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-25.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-26.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-27.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-28.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-29.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-30.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2020-12-31.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2021-01-01.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2021-01-02.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2021-01-03.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2021-01-04.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2021-01-05.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2021-01-06.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2021-01-07.csv.gz\n",
      "Generating /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/trades/10s/2021-01-08.csv.gz\n",
      "/home/federico/Python_vsc_dir/RL_Trader/data_preprocessing.py:102: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  data = pd.concat([trades_data_input_pd, quotes_data_input_pd]).sort_values(by=['Datetime', 'Level'])\n",
      "All data shape: (2851200, 8) - Train dataset shape: (1995840, 6) - Test dataset shape: (855360, 6)\n",
      "rolling window = 950400, calculate as roll: 43200 * levels: 11 * shape[1]: 2\n",
      "done\n",
      "rolling window = 950400, calculate as roll: 43200 * levels: 11 * shape[1]: 2\n",
      "done\n",
      "Saving /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/TRAIN--dyn_z_score-43200--USDT_BTC--10lev--10sec--2020-12-10--2021-01-08.csv.gz\n",
      "Saving /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/TRAIN_TOP--USDT_BTC--10lev--10sec--2020-12-10--2021-01-08.csv.gz\n",
      "rolling window = 950400, calculate as roll: 43200 * levels: 11 * shape[1]: 2\n",
      "done\n",
      "rolling window = 950400, calculate as roll: 43200 * levels: 11 * shape[1]: 2\n",
      "done\n",
      "Saving /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/TEST--dyn_z_score-43200--USDT_BTC--10lev--10sec--2020-12-10--2021-01-08.csv.gz\n",
      "Saving /home/federico/Python_vsc_dir/RL_Trader/Experiments/resampled/USDT_BTC/TEST_TOP--USDT_BTC--10lev--10sec--2020-12-10--2021-01-08.csv.gz\n",
      "train_dyn_df level_2            Datetime  Level  Ask_Price  Bid_Price  Ask_Size  Bid_Size\n",
      "0       2020-12-15 00:00:10     -1   1.366558   1.378428 -0.620445 -0.620123\n",
      "1       2020-12-15 00:00:10      0   1.365364   1.365361 -0.560558  2.370295\n",
      "2       2020-12-15 00:00:10      1   1.379508   1.365317 -0.548553  1.295320\n",
      "test_dyn_df level_2            Datetime  Level  Ask_Price  Bid_Price  Ask_Size  Bid_Size\n",
      "0       2021-01-05 00:00:10     -1   0.655448   0.648169 -0.636104 -0.635302\n",
      "1       2021-01-05 00:00:10      0   0.655765   0.624731  0.042762  2.329173\n",
      "2       2021-01-05 00:00:10      1   0.662876   0.617250 -0.616923 -0.302180\n",
      "top_ob_train              Datetime  Level     Ask_Price  Ask_Size     Bid_Price  Bid_Size  \\\n",
      "0 2020-12-15 00:00:00      0  19275.837040  2.025108  19275.837040  2.785514   \n",
      "1 2020-12-15 00:00:10      0  19277.215985  0.062520  19277.215985  3.122232   \n",
      "2 2020-12-15 00:00:20      0  19283.699654  0.062520  19283.699654  2.200000   \n",
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
      "\n",
      "       Sequence  Unnamed: 0     Mid_Price        Spread  merge_index  \n",
      "0  1.119470e+09           0  19275.837040  5.188259e-13            0  \n",
      "1  1.119470e+09          10  19277.215985  5.187888e-13            1  \n",
      "2  1.119470e+09          20  19283.699654  5.186144e-13            2  \n",
<<<<<<< HEAD
      "top_ob_test               Datetime  Level     Ask_Price  Ask_Size     Bid_Price  Bid_Size  \\\n",
      "0  2021-01-05 00:00:00      0  31999.907748  0.154960  31965.903459       2.0   \n",
      "1  2021-01-05 00:00:10      0  32032.122626  0.457928  31973.901617       2.0   \n",
      "2  2021-01-05 00:00:20      0  32032.122626  0.000201  32022.672112       2.0   \n",
=======
      "top_ob_test              Datetime  Level     Ask_Price  Ask_Size     Bid_Price  Bid_Size  \\\n",
      "0 2021-01-05 00:00:00      0  31999.907748  0.154960  31965.903458       2.0   \n",
      "1 2021-01-05 00:00:10      0  32032.122626  0.457928  31973.901617       2.0   \n",
      "2 2021-01-05 00:00:20      0  32032.122626  0.000201  32022.672112       2.0   \n",
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
      "\n",
      "       Sequence  Unnamed: 0     Mid_Price    Spread  merge_index  \n",
      "0  1.149157e+09           0  31982.905603  0.001063            0  \n",
      "1  1.149157e+09          10  32003.012121  0.001819            1  \n",
      "2  1.149157e+09          20  32027.397369  0.000295            2  \n",
<<<<<<< HEAD
      "CPU times: user 2.48 s, sys: 27.7 ms, total: 2.51 s\n",
      "Wall time: 2.56 s\n"
=======
      "CPU times: user 10min 35s, sys: 12.2 s, total: 10min 47s\n",
      "Wall time: 10min 44s\n"
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
     ]
    }
   ],
   "source": [
    "%%time\n",
<<<<<<< HEAD
    "train_dyn_df, test_dyn_df, top_ob_train, top_ob_test = dp.import_px_data(frequency, pair, date_start, date_end, lob_depth, norm_type, roll)"
=======
    "train_dyn_df, test_dyn_df, top_ob_train, top_ob_test, data = dp.import_px_data(frequency, pair, date_start, date_end, lob_depth, norm_type, roll)"
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Depth Values shape: (138239, 44)\nDatetime Index shape: (138239,)\nDepth Values shape: (34559, 44)\nDatetime Index shape: (34559,)\n"
     ]
    }
   ],
   "source": [
    "# reshape data - is it needed?\n",
    "# train\n",
    "train_depth_dyn, train_dt_index_dyn = dp.reshape_lob_levels(train_dyn_df.reset_index(), output_type='array') # 1 train dataset\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data - is it needed?\n",
    "# train\n",
    "train_depth_dyn, train_dt_index_dyn = reshape_lob_levels(train_dyn_df.reset_index(), output_type='array') # 1 train dataset\n",
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
    "mid_px_train_dyn = pd.Series((train_depth_dyn[:,2] + train_depth_dyn[:,0]) / 2, index=train_dt_index_dyn) # 2\n",
    "px_ts_train = top_ob_train.reset_index()[['Mid_Price']]\n",
    "\n",
    "# test\n",
<<<<<<< HEAD
    "test_depth_dyn, test_dt_index_dyn = dp.reshape_lob_levels(test_dyn_df.reset_index(), output_type='array') # 1 test dataset\n",
=======
    "test_depth_dyn, test_dt_index_dyn = reshape_lob_levels(test_dyn_df.reset_index(), output_type='array') # 1 test dataset\n",
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
    "mid_px_test_dyn = pd.Series((test_depth_dyn[:,2] + test_depth_dyn[:,0]) / 2, index=test_dt_index_dyn) # 2\n",
    "px_ts_test = top_ob_test.reset_index()[['Mid_Price']]"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Datetime\n",
       "2021-01-05 00:00:10    0.651809\n",
       "2021-01-05 00:00:20    0.660226\n",
       "2021-01-05 00:00:30    0.663091\n",
       "2021-01-05 00:00:40    0.665316\n",
       "2021-01-05 00:00:50    0.671964\n",
       "                         ...   \n",
       "2021-01-08 23:59:10    1.598433\n",
       "2021-01-08 23:59:20    1.601037\n",
       "2021-01-08 23:59:30    1.600639\n",
       "2021-01-08 23:59:40    1.602594\n",
       "2021-01-08 23:59:50    1.602502\n",
       "Length: 34559, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "mid_px_test_dyn"
   ]
  },
  {
=======
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
   "source": [
    "## Labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'label_technique' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-6fa8cc84864d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmid_px_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx_ts_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mid_Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothed_px_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_trades_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid_px_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_technique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_technique' is not defined"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 15ae58be42f45ee32f35aaaf30b21af6fa571bfd
   "source": [
    "# train labels\n",
    "mid_px_train = px_ts_train['Mid_Price']\n",
    "labels_train, smoothed_px_train, df_trades_train = cleaned_labels(mid_px_train, method=label_technique, print_details=False)\n",
    "\n",
    "# encode\n",
    "encoded_train_labels = np_utils.to_categorical(labels_train.values,3) \n",
    "\n",
    "# # get transaction df\n",
    "# strategy_df_train = get_strategy_pnl(mid_px_train, labels_train)\n",
    "\n",
    "viz_t.plot_labels_line(mid_px_train[start_plot:end_plot], \n",
    "    labels_train[start_plot:end_plot], \n",
    "    title='Train Labels', \n",
    "    smoothed_signal=smoothed_px_train[start_plot:end_plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test labels\n",
    "mid_px_test = px_ts_test['Mid_Price']\n",
    "labels_test, smoothed_px_test, df_trades_test = cleaned_labels(mid_px_test, method=label_technique, print_details=False)\n",
    "\n",
    "# encode\n",
    "encoded_test_labels = np_utils.to_categorical(labels_test.values,3) \n",
    "\n",
    "# # get transaction df\n",
    "# strategy_df_test = get_strategy_pnl(mid_px_test, labels_test)\n",
    "\n",
    "viz_t.plot_labels_line(mid_px_test[start_plot:end_plot], \n",
    "    labels_test[start_plot:end_plot], \n",
    "    title='Test Labels', \n",
    "    smoothed_signal=smoothed_px_test[start_plot:end_plot])"
   ]
  },
  {
   "source": [
    "## Visual checks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz_t.plot_trades_distribution(df_trades_train[df_trades_train['cleaned_labels']!=0], bin_size=0.0001, metric='gross_returns', fig_width=900, fig_height=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz_t.plot_trades_length_overview(df_trades_train[df_trades_train['cleaned_labels']!=0], x='trade_len',  y='gross_returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.histogram()\n",
    "# fig.add_trace(go.Histogram(x=df_trades_train['trade_len'].values, name='train', autobinx = False, xbins={'size':5}))\n",
    "# fig.add_trace(go.Histogram(x=df_trades_test['trade_len'].values, name='test', autobinx = False, xbins={'size':5}))\n",
    "\n",
    "# # The two histograms are drawn on top of another\n",
    "# fig.update_layout(barmode='overlay')\n",
    "# fig.update_traces(opacity=0.75)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_t.plot_timeseries(ts_list=[top_ob_train.set_index('Datetime')['Mid_Price'], top_ob_test.set_index('Datetime')['Mid_Price'], mid_px_train_dyn, mid_px_test_dyn], primary_axis=[True, True, False, False], legend=['train-px', 'test-px', 'train-dyn', 'test-dyn'], sample_size=180)"
   ]
  },
  {
   "source": [
    "## Model Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_light_deeplob(T, lob_depth):\n",
    "    ## just a test\n",
    "\n",
    "    input_lmd = Input(shape=(T, lob_depth * 4, 1))\n",
    "    conv_first1 = Conv2D(16, (1, 2), strides=(1, 2))(input_lmd)\n",
    "    conv_first1 = LeakyReLU(alpha=0.01)(conv_first1)    \n",
    "    conv_first1 = BatchNormalization()(conv_first1)\n",
    "    # conv_first1 = Dropout(.5)(conv_first1)\n",
    "    \n",
    "    # note on learnable parameters: CONV2(filter shape =1*2, stride=1) layer is: ((shape of width of filter * shape of height filter * number of filters in the previous layer+1) * number of filters) = 2080 or ((2*1*32)+1)*32\n",
    "    conv_first1 = Conv2D(16, (1, 2), strides=(1, 2))(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = BatchNormalization()(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(16, (1, lob_depth))(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = BatchNormalization()(conv_first1)\n",
    "    print(conv_first1.shape)\n",
    "\n",
    "    convfirst_output = Reshape((int(conv_first1.shape[1])* int(conv_first1.shape[3]),))(conv_first1)\n",
    "    print(convfirst_output.shape)\n",
    "    # note on learnable parameters:FC3 layer is((current layer c*previous layer p)+1*c) with c being number of neurons\n",
    "    out = Dense(3, activation='softmax')(convfirst_output)\n",
    "    print(out.shape)\n",
    "    model = Model(inputs=input_lmd, outputs=out)\n",
    "    adam = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model_code = inspect.getsource(create_light_deeplob)\n",
    "lines_with_short_desription = [line for line in model_code.split('\\n') if \"##\" in line]\n",
    "short_description = re.sub(r'\\W+', '_', lines_with_short_desription[0])\n",
    "\n",
    "create_light_deeplob(length, lob_depth).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_now = datetime.now().strftime(\"%y%m%d-%H%M%S\")\n",
    "experiment_id = f'{date_time_now}-{pair}-{frequency.seconds}s-{lob_depth}l-{length}-{date_start}-{date_end}{short_description}'\n",
    "results_folder = f'{experiments_folder}/{pair}/{experiment_id}'\n",
    "os.makedirs(f'{results_folder}', exist_ok=True)\n",
    "batch_size=256\n",
    "\n",
    "config = {\n",
    "  'pair': pair,\n",
    "  'frequency': frequency.seconds,\n",
    "  'lob_depth': lob_depth,\n",
    "  'length': length,\n",
    "  'date_start': date_start,\n",
    "  'date_end': date_end,\n",
    "  'norm_type': norm_type,\n",
    "  'roll': roll,\n",
    "  'batch_size': batch_size,\n",
    "  'label_technique': label_technique\n",
    "#   'min_profit': min_profit,\n",
    "#   'k_plus': k_plus,\n",
    "#   'k_minus': k_minus,\n",
    "#   'alpha': alpha,\n",
    "#   'trading_fee': trading_fee,\n",
    "\n",
    "#   'input': input_file_name,\n",
    "#   'normalized_train_file': normalized_train_file,\n",
    "#   'normalized_test_file':   normalized_test_file,\n",
    "#   'top_ob_train_file': top_ob_train_file,\n",
    "#   'top_ob_test_file': top_ob_test_file\n",
    "}\n",
    "\n",
    "with open(f'{results_folder}/config.json', 'w') as fp:\n",
    "    json.dump(config, fp, default=str)\n",
    "\n",
    "with open(f'{results_folder}/model_code.py', 'w') as fp:\n",
    "    fp.write(model_code)\n",
    "\n",
    "light_deeplob = create_light_deeplob(length, lob_depth)\n",
    "with open(f'{results_folder}/model_summary.txt', 'w') as fp:\n",
    "    light_deeplob.summary(print_fn=lambda x: fp.write(x + '\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to train the model on smoother version of the data"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_deeplob = create_light_deeplob(length, lob_depth)\n",
    "\n",
    "model_checkpoint_path = f'{results_folder}/{experiment_id}.h5'\n",
    "\n",
    "# Learning rate callback. Reduce on Plateau multiply the lr by the factor if val loss does not improve for n epochs (patience)\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                   factor=0.2, \n",
    "                                                   patience=20)\n",
    "\n",
    "# Checkpoint callback. Saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(model_checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=2,\n",
    "                                                 save_freq='epoch') # every epoch\n",
    "\n",
    "# Early stopping callback. When sees no progress on the validation set\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=50,\n",
    "                                               restore_best_weights=True)\n",
    "\n",
    "# Tensorboard callback\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(results_folder)\n",
    "\n",
    "# Train and Test time series generators\n",
    "generator_train = TimeseriesGenerator(\n",
    "    train_depth_dyn,\n",
    "    encoded_train_labels,\n",
    "    length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# to be replaced with validation?\n",
    "generator_test = TimeseriesGenerator(\n",
    "    test_depth_dyn,\n",
    "    encoded_test_labels,\n",
    "    length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = '/home/federico/Python_vsc_dir/RL_Trader/Experiments/USDT_BTC/210119-184504-USDT_BTC-10s-10l-300-2020_04_04-2021_01_03_binary_classification_full_inception_lighter_deep_lob_model_with_longer_timesteps_300_/210119-184504-USDT_BTC-10s-10l-300-2020_04_04-2021_01_03_binary_classification_full_inception_lighter_deep_lob_model_with_longer_timesteps_300_.h5'\n",
    "# loaded_light_deep_lob = tf.keras.models.load_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "light_deeplob.fit(generator_train, \n",
    "            epochs=200, \n",
    "            verbose=0,\n",
    "            validation_data=generator_test,\n",
    "            callbacks=[lr_callback, cp_callback, es_callback, tb_callback])"
   ]
  },
  {
   "source": [
    "## Evaluating"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '/home/federico/Python_vsc_dir/RL_Trader/Experiments/USDT_BTC/210221-200759-USDT_BTC-10s-10l-100-2020_04_04-2021_01_03_big_lr_big_batch_size_16_filter_size_shuffle/210221-200759-USDT_BTC-10s-10l-100-2020_04_04-2021_01_03_big_lr_big_batch_size_16_filter_size_shuffle.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously saved weights and evaluate model performance\n",
    "deep_lob_loaded = tf.keras.models.load_model(model_name)\n",
    "generator_test = TimeseriesGenerator(\n",
    "    test_depth_dyn,\n",
    "    encoded_test_labels,\n",
    "    length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def evaluate_model(model):\n",
    "    # Re-evaluate the model\n",
    "    loss, acc = model.evaluate(generator_test, verbose=2)\n",
    "    print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "#evaluate_model(deep_lob_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels\n",
    "predictions_prob = deep_lob_loaded.predict(generator_test, verbose=1)\n",
    "map_labels = np.vectorize(back_to_labels) # vectorize back to labels from func_tools\n",
    "predicted_labels = pd.Series(map_labels(np.argmax(predictions_prob,axis=1)), name='predicted_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental: predicted labels on rolling avg\n",
    "predictions_prob_wa = pd.DataFrame(predictions_prob).rolling(window=10).mean().values\n",
    "map_labels = np.vectorize(back_to_labels) # vectorize back to labels from func_tools\n",
    "predicted_labels_wa = pd.Series(map_labels(np.argmax(predictions_prob_wa,axis=1)), name='predicted_labels_wa') # back to original 1,0,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##### Predicted labels #####')\n",
    "label_insights(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##### Weighted average predicted labels #####')\n",
    "label_insights(predicted_labels_wa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels.shape, test_depth_dyn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dangerous assigning offset here, wrap it into a function\n",
    "# align prediction with \"length\" offset\n",
    "index_range = np.arange(length, predicted_labels.shape[0] + length) # offset ts length fed to ts generator\n",
    "predicted_labels.index = index_range\n",
    "\n",
    "# generate timeseries with buy, sell, zero prob\n",
    "buy_prob = pd.Series(predictions_prob[:,1], index=index_range)\n",
    "sell_prob = pd.Series(predictions_prob[:,2], index=index_range)\n",
    "zero_prob = pd.Series(predictions_prob[:,0], index=index_range)\n",
    "\n",
    "buy_prob_wa = pd.Series(predictions_prob_wa[:,1], index=index_range)\n",
    "\n",
    "viz_t.plot_labels_line(top_ob_test['Mid_Price'][start_plot:end_plot], \n",
    "    labels_test[start_plot:end_plot], # original labels\n",
    "    title='Train Set Labels', \n",
    "    #smoothed_signal=smoothed_px_test[start_plot:end_plot],\n",
    "    predicted_labels=predicted_labels[start_plot:end_plot],\n",
    "    buy_prob_labels=buy_prob[start_plot:end_plot],\n",
    "    #sell_prob_labels=sell_prob[start:end],\n",
    "    predictions_prob_wa=buy_prob_wa[start_plot:end_plot],\n",
    "    width=1100, height=600\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DOUBLE CHECK that labels and px_ts are correctly aligned\n",
    "px_ts = top_ob_test['Mid_Price']# adjust prediction offsset\n",
    "datetime_ts = top_ob_test['Datetime']\n",
    "trades_timeseries = get_strategy_pnl(px_ts, predicted_labels)\n",
    "df_trades = trades_timeseries.dropna(subset=['gross_returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px_ts = top_ob_test['Mid_Price'][length:].reset_index()['Mid_Price']# adjust prediction offsset\n",
    "# datetime_ts = top_ob_test['Datetime'][length:].reset_index()['Datetime']\n",
    "# trades_timeseries = get_strategy_pnl(px_ts, predicted_labels)\n",
    "# df_trades = trades_timeseries.dropna(subset=['gross_returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to do:\n",
    "# seek for patterns in prediction probability\n",
    "# day vs night - weekday vs weekend - model certainty before long trades vs short trades\n",
    "# determine if predictions are naive"
   ]
  }
 ]
}