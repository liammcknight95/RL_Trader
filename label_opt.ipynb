{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('rltrader_env')",
   "metadata": {
    "interpreter": {
     "hash": "8e2992cd1537a0ce0fcfbbc90dae1b0e6789ae476b7bf9d031acd3fda788ff6d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import plotly_express as px\n",
    "import scipy.signal\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from func_tools import plot_labels_line, get_strategy_pnl,label_insights"
   ]
  },
  {
   "source": [
    "## Data Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_folder = 'Experiments'\n",
    "cache_folder = f'{experiments_folder}/cache'\n",
    "\n",
    "pair = 'USDT_BTC'\n",
    "lob_depth = 10\n",
    "frequency = timedelta(seconds=10)\n",
    "frequency_seconds = int(frequency.total_seconds())\n",
    "date_start = '2020_04_04'\n",
    "date_end = '2021_01_03'\n",
    "norm_type = 'dyn_z_score'\n",
    "k_plus = 15\n",
    "k_minus = 15\n",
    "alpha = 0 # Zero to allow only for 1 and -1 labels\n",
    "trading_fee=0.000712\n",
    "roll = 7200 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import - needs to be adjusted importing from several files using Dask\n",
    "input_file_name = f'{pair}--{lob_depth}lev--{frequency_seconds}sec--{date_start}--{date_end}.csv.gz'\n",
    "\n",
    "normalized_train_file = f'{cache_folder}/{pair}/TRAIN--{norm_type}-{roll}--{input_file_name}'\n",
    "normalized_test_file = f'{cache_folder}/{pair}/TEST--{norm_type}-{roll}--{input_file_name}'\n",
    "\n",
    "top_ob_train_file = f'{cache_folder}/{pair}/TRAIN_TOP--{input_file_name}'\n",
    "top_ob_test_file = f'{cache_folder}/{pair}/TEST_TOP--{input_file_name}'\n",
    "\n",
    "#if os.path.isfile(normalized_test_file): # testing for one of cache files, assuming all were saved \n",
    "print(f'Reading cached {normalized_train_file}')\n",
    "train_dyn_df = pd.read_csv(normalized_train_file)\n",
    "# print(f'Reading cached {normalized_test_file}')\n",
    "# test_dyn_df = pd.read_csv(normalized_test_file)\n",
    "\n",
    "print(f'Reading cached {top_ob_train_file}')\n",
    "top_ob_train = pd.read_csv(top_ob_train_file)\n",
    "# print(f'Reading cached {top_ob_test_file}')\n",
    "# top_ob_test = pd.read_csv(top_ob_test_file)\n",
    "\n",
    "\n",
    "# get dynamic mid price for get label\n",
    "top_ob_train_dyn = train_dyn_df[train_dyn_df['Level'] == 0]\n",
    "top_ob_train_dyn['Mid_Price'] = (top_ob_train_dyn['Ask_Price'] + top_ob_train_dyn['Bid_Price']) / 2\n",
    "mid_px_train_dyn = top_ob_train_dyn.reset_index()['Mid_Price']\n",
    "\n",
    "# get actual mid price\n",
    "mid_px_train = top_ob_train['Mid_Price']"
   ]
  },
  {
   "source": [
    "### Savitzky–Golay filter (from Wiki)\n",
    "A Savitzky–Golay filter is a digital filter that can be applied to a set of digital data points for the purpose of smoothing the data, that is, to increase the precision of the data without distorting the signal tendency. This is achieved, in a process known as convolution, by fitting successive sub-sets of adjacent data points with a low-degree polynomial by the method of linear least squares. When the data points are equally spaced, an analytical solution to the least-squares equations can be found, in the form of a single set of \"convolution coefficients\" that can be applied to all data sub-sets, to give estimates of the smoothed signal, (or derivatives of the smoothed signal) at the central point of each sub-set. \n",
    "\n",
    "### Local regression (from Wiki)\n",
    "Local regression or local polynomial regression,[1] also known as moving regression,[2] is a generalization of moving average and polynomial regression.[3] Its most common methods, initially developed for scatterplot smoothing, are LOESS (locally estimated scatterplot smoothing) and LOWESS (locally weighted scatterplot smoothing), both pronounced /ˈloʊɛs/. They are two strongly related non-parametric regression methods that combine multiple regression models in a k-nearest-neighbor-based meta-model. Outside econometrics, LOESS is known and commonly referred to as Savitzky–Golay filter [4][5] (proposed 15 years before LOESS). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old approach with averages\n",
    "\n",
    "# span_plus = 30\n",
    "# span_minus = 60\n",
    "# labels, minus_smooth, plus_smooth = get_labels(savgol_mid_px_3_41, span_plus, span_minus, a, technique='ema', long_only=False, return_smooth=True)\n",
    "#labels = labels.fillna(0)"
   ]
  },
  {
   "source": [
    "## Labelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1 - labels based on smoothed signal direction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.0 # threshold\n",
    "\n",
    "# smooth prices - Savitzky–Golay filter\n",
    "savgol_mid_px = pd.Series(scipy.signal.savgol_filter(mid_px_train, 31, 1)) \n",
    "\n",
    "# scale smoothed time series (squash between 0 and 1 with min max scaler)\n",
    "values = savgol_mid_px.values.reshape(savgol_mid_px.shape[0],1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "normalized_savgol = scaler.transform(values).reshape(values.shape[0])\n",
    "\n",
    "# first level difference - smoothed time series direction\n",
    "d = np.diff(normalized_savgol)\n",
    "\n",
    "# label based on the direction\n",
    "labels = pd.Series(np.where(d>a, 1, np.where(d<a, -1, 0)),  name='labels')\n",
    "label_insights(labels.dropna())\n",
    "\n",
    "# recap dataframe\n",
    "df_strategy = get_strategy_pnl(mid_px_train, labels)\n",
    "\n",
    "#only keep one raw per trade (gross return NAs)\n",
    "df_trades = df_strategy[['trade_grouper', 'labels', 'trade_len', 'gross_returns']].dropna(subset=['gross_returns'])\n",
    "\n",
    "# plot trades 1 histogram\n",
    "histo_trades = px.histogram(x=df_trades['gross_returns'], title='All trades')\n",
    "histo_trades.show()"
   ]
  },
  {
   "source": [
    "### Step 2 - replace short and unprofitable labels with previous values\n",
    "#### short labels seem to interrupt longer trends with no reason"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate short unprofitable labels, replace them with NAs and fill them with prev label values\n",
    "df_trades['cleaned_labels'] = df_trades['labels']\n",
    "df_trades.loc[(df_trades['trade_len'] <= 20) & (df_trades['gross_returns'] <= 0.002), 'cleaned_labels'] = pd.NA\n",
    "df_trades['cleaned_labels'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "#df_trades.groupby('cleaned_labels')['trade_len'].sum()\n",
    "\n",
    "# transform table trades - one row per trade -  back into a full labels timeseries\n",
    "cleaned_labels = np.empty(labels.shape[0])\n",
    "cleaned_labels[:] = np.nan\n",
    "cleaned_labels = pd.Series(cleaned_labels, name='cleaned_labels')\n",
    "cleaned_labels.loc[df_trades['trade_grouper']] = df_trades['cleaned_labels']\n",
    "cleaned_labels = cleaned_labels.fillna(method='ffill')\n",
    "\n",
    "# print step 2 label insights\n",
    "label_insights(cleaned_labels)\n",
    "df_strategy_2 = get_strategy_pnl(mid_px_train, cleaned_labels)\n",
    "df_trades2 = df_strategy_2[['trade_grouper', 'labels', 'trade_len', 'gross_returns']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot trades 2 histogram\n",
    "histo_trades2 = px.histogram(x=df_trades2[df_trades2['gross_returns']!=0]['gross_returns'], title='All trades', histfunc='count')\n",
    "histo_trades2.show()\n",
    "\n",
    "# plot a portion of the timeseries at step 2\n",
    "end= 30000\n",
    "start= 0\n",
    "plot_labels_line(mid_px_train[start:end], cleaned_labels[start:end], title='Testing2', \n",
    "savgol_mid_px=savgol_mid_px[start:end]\n",
    ")"
   ]
  },
  {
   "source": [
    "### Step 3 - take all remaining trades with small return and fill those with zero labels\n",
    "#### The shorter trades would have already been replaced at step 2. The remaining ones are\n",
    "#### too long to just be \"attached\" to the previous labels and should be defined neither as buy nor as sell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace remaining unprofitable trades with zeros\n",
    "df_trades2['cleaned_labels'] = df_trades2['labels']\n",
    "df_trades2.loc[df_trades2['gross_returns'] <= 0.0020, 'cleaned_labels'] = pd.NA\n",
    "df_trades2['cleaned_labels'].fillna(0, inplace=True)\n",
    "\n",
    "# transform table trades back into a full labels timeseries\n",
    "cleaned_labels2 = np.empty(labels.shape[0])\n",
    "cleaned_labels2[:] = np.nan\n",
    "cleaned_labels2 = pd.Series(cleaned_labels2, name='cleaned_labels')\n",
    "cleaned_labels2.loc[df_trades2['trade_grouper']] = df_trades2['cleaned_labels']\n",
    "cleaned_labels2 = cleaned_labels2.fillna(method='ffill')\n",
    "\n",
    "# print step 3 label insights\n",
    "label_insights(cleaned_labels2)\n",
    "df_strategy_3 = get_strategy_pnl(mid_px_train, cleaned_labels2)\n",
    "df_trades3 = df_strategy_3[['trade_grouper', 'labels', 'trade_len', 'gross_returns']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot trades 3 histogram\n",
    "histo_trades3 = px.histogram(x=df_trades3[df_trades3['gross_returns']!=0]['gross_returns'], title='All trades', histfunc='count')\n",
    "histo_trades3.show()\n",
    "\n",
    "# plot a portion of the timeseries at step 3\n",
    "end=30000\n",
    "start=0\n",
    "plot_labels_line(mid_px_train[start:end], cleaned_labels2[start:end], title='Testing3', \n",
    "savgol_mid_px=savgol_mid_px[start:end]\n",
    ")"
   ]
  },
  {
   "source": [
    "### Improvements:\n",
    "#### explore ho looking at 2nd, 3d 5th difference rather than first would impact labels\n",
    "#### handle labels where step 2 rather than linking same sign labels, are just delaying it, deserving a zero instead\n",
    "#### different parameters (min profitability and length) for day and night. Nights tend to be less volatile than days"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Exploratory data analysis - experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_df = top_ob_train[['Datetime', 'Mid_Price']].copy() # create a copy of the df\n",
    "label_pred_df['Datetime'] = pd.to_datetime(label_pred_df['Datetime'])\n",
    "#label_pred_df = label_pred_df.set_index('Datetime')\n",
    "label_pred_df.columns = ['ds', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet(changepoint_prior_scale=0.01).fit(label_pred_df[:20000])\n",
    "future = m.make_future_dataframe(periods=60, freq='10s')\n",
    "fcst = m.predict(future)\n",
    "fig = m.plot(fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = m.plot_components(fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "# prepare data\n",
    "data = mid_px_train.values\n",
    "# create class\n",
    "model = ExponentialSmoothing(data, ...)\n",
    "# fit model\n",
    "model_fit = model.fit(...)\n",
    "# make predictions\n",
    "yhat = model_fit.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try smoothing for labels\n",
    "# try to smooth pct probg pred"
   ]
  },
  {
   "source": [
    "## Datashader - visualize very large datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "from collections import OrderedDict\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default plot ranges:\n",
    "x_range = (0, df_profit_opt.shape[0])\n",
    "y_range = (0.8*df_profit_opt['px'].min(), 1.2*df_profit_opt['px'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cvs = ds.Canvas(x_range=x_range, y_range=y_range, plot_height=900, plot_width=2400)\n",
    "cols = ['px', 'cleaned_labels']\n",
    "aggs= OrderedDict((c, cvs.line(df_profit_opt.reset_index(), 'index', c)) for c in cols)\n",
    "img = ds.transfer_functions.shade(aggs['px'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(img)\n",
    "z = arr.tolist()\n",
    "dims = len(z[0]), len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ dict( \n",
    "        z = z, \n",
    "        x = np.linspace(x_range[0], x_range[1], dims[0]),\n",
    "        y = np.linspace(y_range[0], y_range[1], dims[1]),\n",
    "        colorscale = [ [0, 'rgba(255,255,255,0)'], [1, 'rgba(0,0,255,1)'] ],\n",
    "        showscale = False,\n",
    "        # reversescale = True,\n",
    "        type = 'heatmap' ) ]\n",
    "\n",
    "layout = dict(  \n",
    "    margin = dict( t=0, b=0 ),\n",
    "    yaxis = dict( \n",
    "        fixedrange=False,\n",
    "        ),\n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "            ),\n",
    "        )   \n",
    "    )\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Scatter(y=px_ts, x=px_ts.index, name='Price'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(y=labels, x=labels.index, name='Labels', marker=dict(color='rgba(240, 52, 52, 0.3)')), \n",
    "    secondary_y=True)\n",
    "\n",
    "\n",
    "fig.update_layout(title=f'<b>{title}</b>')\n",
    "fig.update_yaxes(title_text='ccy', fixedrange= False, secondary_y=False)\n",
    "fig.update_yaxes(title_text='label', secondary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_px_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}